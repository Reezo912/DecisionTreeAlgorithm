{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path donde se encuentran mis archivos train\n",
    "BASE_PATH = \"../data/processed\"\n",
    "TRAIN_PATHS = [\n",
    "    \"X_train_con_outliers_raw.xlsx\",\n",
    "    \"X_train_sin_outliers_raw.xlsx\",\n",
    "]\n",
    "\n",
    "# Guardo cada uno de estos archivos dentro de una lista\n",
    "TRAIN_DATASETS = []\n",
    "for path in TRAIN_PATHS:\n",
    "    TRAIN_DATASETS.append(\n",
    "        # pd.read_excel(BASE_PATH + \"/\" + path)\n",
    "        pd.read_excel(f\"{BASE_PATH}/{path}\")\n",
    "        # pd.read_excel(os.path.join(BASE_PATH, path))\n",
    "    )\n",
    "\n",
    "# Path donde se encuentran mis archivos test\n",
    "TEST_PATHS = [\n",
    "    \"X_test_con_outliers_raw.xlsx\",\n",
    "    \"X_test_sin_outliers_raw.xlsx\",\n",
    "]\n",
    "\n",
    "# Guardo cada uno de estos archivos dentro de una lista\n",
    "TEST_DATASETS = []\n",
    "for path in TEST_PATHS:\n",
    "    TEST_DATASETS.append(\n",
    "        pd.read_excel(f\"{BASE_PATH}/{path}\")\n",
    "    )\n",
    "\n",
    "y_train = pd.read_excel(f\"{BASE_PATH}/y_train.xlsx\")\n",
    "y_test = pd.read_excel(f\"{BASE_PATH}/y_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train_accuracy  test_accuracy  train_MSE  test_MSE\n",
      "0             1.0       0.876623        0.0  0.123377\n",
      "1             1.0       0.883117        0.0  0.116883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for index, dataset in enumerate(TRAIN_DATASETS):\n",
    "    model_Random = RandomForestClassifier(random_state=42)\n",
    "    model_Random.fit(dataset, y_train)\n",
    "    y_pred_train = model_Random.predict(dataset)\n",
    "    y_pred_test = model_Random.predict(TEST_DATASETS[index])\n",
    "    \n",
    "    results.append({\n",
    "        \"train_accuracy\": accuracy_score(y_train, y_pred_train),\n",
    "        \"test_accuracy\": accuracy_score(y_test, y_pred_test),\n",
    "        \"train_MSE\": mean_squared_error(y_train, y_pred_train),\n",
    "        \"test_MSE\": mean_squared_error(y_test, y_pred_test)\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_param_grid = {\n",
    "    'bootstrap': [True],  # Se mantiene True si es el que mejor funcionó\n",
    "    'class_weight': [None],  # Forzar el balance de clases\n",
    "    'criterion': ['entropy'],  # Usamos 'entropy' si ha dado mejores resultados\n",
    "    'max_depth': [2,3,4, 5, 6, 7],  # Explorar valores cercanos al 5, ya que este rango suele controlar el sobreajuste\n",
    "    'max_features': [0.65, 0.70, 0.75],  # Afinamos alrededor del 0.65 para aumentar la aleatoriedad y diversidad\n",
    "    'min_samples_leaf': [1, 2],  # Evitar hojas muy pequeñas que puedan sobreajustar\n",
    "    'min_samples_split': [4, 5],  # Requiere mayor número de muestras para realizar la división\n",
    "    'n_estimators': [100, 125, 150]  # Incrementar la cantidad de árboles para estabilizar la predicción\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train_accuracy  test_accuracy  train_f1   test_f1  train_MSE  test_MSE\n",
      "0        0.973941       0.896104  0.961722  0.849057   0.026059  0.103896\n",
      "-----------------------\n",
      "Error cuadrático medio: 0.1038961038961039\n",
      "-----------------------\n",
      "Mejores hiperparámetros: {'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'max_features': 0.65, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "best_index_random = 1\n",
    "\n",
    "model_forest_optimized = RandomForestClassifier(random_state=42)\n",
    "\n",
    "forest_grid_optimized = GridSearchCV(estimator = model_forest_optimized, param_grid = random_param_grid, scoring = 'accuracy', cv = 5, n_jobs = 14)\n",
    "\n",
    "forest_grid_optimized.fit(TRAIN_DATASETS[best_index_random], y_train.values.ravel())\n",
    "\n",
    "r_forest_model = forest_grid_optimized.best_estimator_\n",
    "\n",
    "y_pred_random_train = r_forest_model.predict(TRAIN_DATASETS[best_index_random])\n",
    "y_pred_random_test = r_forest_model.predict(TEST_DATASETS[best_index_random])\n",
    "\n",
    "\n",
    "results_random_optimized = []\n",
    "\n",
    "results_random_optimized.append({\n",
    "        \"train_accuracy\": accuracy_score(y_train, y_pred_random_train),\n",
    "        \"test_accuracy\": accuracy_score(y_test, y_pred_random_test),\n",
    "        \"train_f1\": f1_score(y_train, y_pred_random_train),\n",
    "        \"test_f1\": f1_score(y_test, y_pred_random_test),\n",
    "        \"train_MSE\": mean_squared_error(y_train, y_pred_random_train),\n",
    "        \"test_MSE\": mean_squared_error(y_test, y_pred_random_test)\n",
    "    })\n",
    "\n",
    "df_random_optimized = pd.DataFrame(results_random_optimized)\n",
    "\n",
    "print(df_random_optimized)\n",
    "print('-----------------------')\n",
    "print(f\"Error cuadrático medio: {mean_squared_error(y_test, y_pred_random_test)}\")\n",
    "print('-----------------------')\n",
    "print(\"Mejores hiperparámetros:\", forest_grid_optimized.best_params_)\n",
    "\n",
    "# Original\n",
    "#   train_accuracy  test_accuracy  train_f1  test_f1  train_MSE  test_MSE\n",
    "#0        0.912052       0.883117  0.869565     0.82   0.087948  0.116883\n",
    "#-----------------------\n",
    "#Error cuadrático medio: 0.11688311688311688    \n",
    "\n",
    "# None\n",
    "#   train_accuracy  test_accuracy  train_f1   test_f1  train_MSE  test_MSE\n",
    "#0        0.973941       0.896104  0.961722  0.849057   0.026059  0.103896\n",
    "#-----------------------\n",
    "#Error cuadrático medio: 0.1038961038961039\n",
    "\n",
    "# Balanced\n",
    "#   train_accuracy  test_accuracy  train_f1   test_f1  train_MSE  test_MSE\n",
    "#0        0.991857        0.88961  0.988235  0.841121   0.008143   0.11039\n",
    "#-----------------------\n",
    "#Error cuadrático medio: 0.11038961038961038"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedo observar algo de overfitting en mi modelo obteniendo buenos resultados, esto puede ser posiblemente porque hay un desbalanceo de clases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
